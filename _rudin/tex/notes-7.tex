\subsection{Pointwise Convergence}

\begin{definition} 
    Let $f_n: E \rightarrow \mathbb{R}$ be a sequence of functions. 
    If $f$ is a function such that $f_n(x) \to f(x)$ as $n \to \infty$ for all $x \in E$, then we say $f_n$ converges \textit{pointwise} to $f$.
\end{definition}

This type of convergence is very \textit{weak}. It guarantees very little in the way of actually \textit{working with} the limit.

This definition is readily adapted to infinite sums of functions.

\begin{definition}
    If $f$ is a function such that 
    \[\sum_{n=1}^\infty f_n(x) = f(x)\] 
    for all $x \in E$, then we say $f$ is the \textit{sum} of the series $f_n$.
\end{definition}

An example of the weakness of pointwise convergence is

\subsubsection{Continuity is not preserved under pointwise convergence}
\begin{example} 
    Let $f_n: [0, 1] \rightarrow [0, 1]$ be defined by
    \[f_n(x) := x^n\]

    Then $f := \lim f_n$ is 
    \[f(x) = \begin{cases}
        0 & x < 1 \\
        1 & x = 1
    \end{cases}\]

    by Theorem 3.20(e)
\end{example}

In this case, a sequence of continuous functions converges to a function that is eminently discontinuous. We use the preceding idea of ``letting $f < 0$ sink and letting $f = 1$ float using the $n^{th}$ power limit'' to show the following.

\begin{example}Integrability is not preserved under pointwise convergence

    \[\lim_{m \to \infty} \lim_{n \to \infty} (\cos m!\pi x ) ^{2n} = \begin{cases}
        0 & x\text{ irrational} \\
        1 & x\text{ rational}
    \end{cases}\]

    If we let 
    \[f_m (x) := \lim_{n \to \infty} (\cos m!\pi x)^{2n}\]
    the above shows that a limit of integrable functions ($\int f_m dx = 0$ for all $m$) may fail to be integrable.

    \textbf{Proof}

    By a similar argument as in the previous example,
    \[\lim_{n \to \infty} (\cos m!x)^{2n} = \begin{cases}
        0 & m!x\text{ is not an integer} \\
        1 & m!x\text{ is an integer} \\
    \end{cases}\]

    Let $x = p/q$ be rational. Then $m!x$ is rational for all $m \geq q$. Let $x$ be irrational, $m!x$ cannot be an integer for any $m$, otherwise we can show a contradiction. Then

    \[\lim_{m \to \infty} \begin{cases}
        0 & m!x\text{ is not an integer} \\
        1 & m!x\text{ is an integer} \\
        \end{cases} = \begin{cases}
        0 & x \text{ irrational} \\
        1 & x \text{ rational} \\
    \end{cases}\]
\end{example} 

These two examples show that \textit{properties} of $f_n$ may not pass through the limit to $f$. 

Next, we show that \textit{operations} on $f_n$ may not be passed through the limit to $f$.

\begin{example} A limit of differentiated functions may not be the differentiated limit of functions

    Let 
    \[f_n(x) := \frac{\sin nx}{\sqrt{n}}\]
    Then,
    \[0 = \frac{d}{dx}\left[\lim_{n \to \infty} f_n \right]\neq \lim_{n \to \infty} \left[\frac{d}{dx} f_n\right] = \sqrt{n}\cos nx\]
\end{example}

\begin{example} A limit of integrated functions may not be the integral of a limit of functions

    Let 
    \[f_n(x) := n x(1-x^2)^n\]
    Then
    \[0 = \int_0^1 \left[\lim_{n \to \infty} f_n \right] \neq \lim_{n \to \infty} \left[\int_0^1 f_n \right] = \frac{1}{2} \]
\end{example}

\subsection{Uniform convergence}

\begin{definition} Uniform convergence of functions

    Let $f_n: E \rightarrow \mathbb{R}$ be a sequence of functions. 

    If $f$ is a function such that for all $\varepsilon$ there exists $N$ such that
    \[|f_n(x) - f(x)| \leq \varepsilon\]
    for all $x$, we say that $f$ converges \textit{uniformly}.
\end{definition}

    This definition carries over to sums of functions (the partial sums must converge to the limit function uniformly).

This is a \textit{much stronger} notion of convergence, as it ``tethers'' together convergence of of all points in the domain. 

\subsection{Equicontinuous families of functions}

Now we go up another level. How do we \textit{produce} these uniformly convergent sequences of functions out of existing sequences? The same way we have conditions (boundedness in $\mathbb{R}^n$) for squeezing out convergent sequences of numbers? First consider two different kinds of boundedness.

\begin{definition}Pointwise and uniform boundedness
    
    Let $f_n: E \rightarrow \mathbb{R}$ be a sequence of functions.

    $f_n$ is \textit{pointwise bounded} if for some $\varphi: E \rightarrow \mathbb{R}$,
    \[|f_n(x)| < \varphi(x)\]
    $f_n$ is \textit{uniformly bounded} if for some $M \geq 0$,
    \[|f_n(x)| < M\]
    It is clear that uniform boundedness implies pointwise boundedness, by letting $\phi(x) := M$.
\end{definition}

There are, however, no easy analogues, even when we put together all the restrictions we've considered so far:

\begin{example}A uniformly bounded sequence of continuous functions on a compact set without a convergent subsequence

    Let $f_n: [0, 2\pi] \to \mathbb{R}$ be defined 
    \[f_n(x) := \sin nx\]
    Suppose this sequence has a subsequence $f_{n_k}$ that converges pointwise. Then it must be that
    \[\lim_{k \to \infty} (\sin n_k x - \sin n_{k+1}x) = 0\]
    therefore it must be the case that
    \[\lim_{k \to \infty} (\sin n_k x - \sin n_{k+1}x)^2 = 0\]
    By Lebesgue's theorem concerning integration of boundedly convergent sequences (Theorem 11.32), this implies
    \[\lim_{k \to \infty} \int_0^{2\pi} (\sin n_k x - \sin n_{k+1} x)^2 dx = 0\]
    But 
    \[\int_0^{2\pi} (\sin n_k x - \sin n_{k+1} x)^2 dx = 2\pi\]
    which is a contradiction.
\end{example}

Even if we have a (pointwise) convergent sequence, we cannot produce a uniformly convergent subsequence necessarily, even with uniform boundedness on a compact set.

\begin{example}A uniformly bounded pointwise converging sequence on a compact set without a uniformly convergent subsequence

    Let $f_n: [0, 1] \rightarrow \mathbb{R}$ be
    \[f_n(x) = \frac{x^2}{x^2+(1-nx)^2}\]
    Then $|f_n| \leq 1$ for all $n$, and $f_n$ is a uniformly bounded sequence. $f_n(x) \to 0$ for all $x$ as $n \to \infty$ as well, so this sequence converges pointwise.
    However,
    \[f_n\left(\frac{1}{n}\right) = 1\]
    so that no subsequence can possibly converge uniformly.
\end{example}

However, we know that compact sets are separable (have a dense countable subset), hence the following consequence of pointwise boundedness will be useful:

\begin{theorem}Every pointwise bounded sequence has a subsequence that converges pointwise on a countable set

    Let $f_n$ be defined on a countable set $E$. (Or define it on an arbitrary set, and let $f_n$ be the restriction on a countable set $E$).

    Then there exists a subsequence $f_{n_k}$ of $f_n$ such that $f_{n_k}$ converges pointwise on $E$.

    \textbf{Proof}

    We will construct a table of $f_n$ of which taking the diagonal will give us the subsequence we want. To do so, we introduce a lemma

    \begin{lemma}
    \textbf{Lemma}

    Let $s_n$ be a bounded sequence. Then it contains a convergent subsequence $s_{n_k}$ that may be obtained by simply deleting entries in $s_n$.
    \end{lemma}

    This table will be defined row-by-row

    Let $x_i$ be an enumeration of $E$. Since $f_n$ is pointwise bounded, we can produce a subsequence $f_{n_k}$ such that $f_{n_k}(x_1)$ converges as $k \to \infty$. Denote this sequence by $f^1_k$. 

    Then in a similar fashion, we recursively construct the following sequences $f^{i+1}_k$ out of $f^i_k$ using the above lemma. This results in a table of functions
    \[\begin{matrix}
        f^1_1 & f^1_2 & f^1_3 & \cdots \\
        f^2_1 & f^2_2 & f^2_3 & \cdots \\
        f^3_1 & f^3_2 & f^3_3 & \cdots \\
        \vdots & \vdots & \vdots & \ddots
    \end{matrix}\]

    which satisfy the properties
    \begin{itemize}
        \item[(a)] $f^{i+1}_k$ is a subsequence of $f^i_k$, moreover it is simply $f^i_k$ with entries deleted. 
        \item[(b)] $f^i_k(x_i)$ converges as $k \to \infty$
    \end{itemize}

    Then, if we take the diagonal
    \[f^1_1, f^2_2,  f^3_3, \ldots\] 
    (a) implies that this sequence is a subsequence of all $f^i_k$, thus (b) implies that this sequence converges for all $x_i$.
\end{theorem}

Now we introduce an important property 

\begin{definition} Equicontinuous families of functions

    Let $\mathscr{F}$ be a family of complex-valued functions $f$ defined on a set $E$. $\mathscr{F}$ is \textit{equicontinuous} if for every $\varepsilon > 0$ there exists $\delta > 0$ such that
    \[|f(x) - f(y)| < \varepsilon\]
    whenever $d(x, y) < \delta$.
\end{definition}

We get one result almost ``for free'' with this definition

\begin{theorem}Uniformly convergent continuous function sequences on a compact domain form an equicontinuous family

    Let $K$ be a compact metric space, and let $f_n \in \mathscr{C}(K)$ be a uniformly convergent sequence on $K$. Then $f_n$ is equicontinuous on $K$
\end{theorem}

\begin{proof}
    Let $\varepsilon > 0$. Since $f_n$ converges in $\mathscr{C}(K)$, we can choose $N$ such that
    \[\Vert f_n - f_N \Vert < \varepsilon\]
    whenever $n > N$. Now, use the fact that continuous functions on compact sets are uniformly continuous (Theorem 4.19) to find $\delta_N > 0$ such that 
    \[|f_N(x) - f_N(y)| < \varepsilon\]
    whenever $d(x, y) < \delta_N$. This alone evidently covers the case $n = N$. For $n > N$, we have the following inequality,
    \[|f_n(x) - f_n(y)| \leq |f_n(x) - f_N(x)| + |f_N(x) - f_N(y)| + |f_N(y) - f_n(y)| < 3\varepsilon\]
    Hence we have shown that $\delta_N$ suffices for $n \geq N$. For $n < N$, use uniform continuity for each $f_n$ to get $\delta_n$ be such that $d(x, y) < \delta_n$ implies
    \[|f_i(x) - f_i(y)| < \varepsilon\]
    Finally, let $\delta = \min \{\delta_1, \ldots, \delta_N\}$. This $\delta$ satisfies the condition for all $n > 0$.
\end{proof}

The next result uses the earlier theorem about pointwise converging subsequences on a countable set.

\begin{theorem} The Arzela-Ascoli theorem

    Let $K$ be a compact metric space. Let $f_n \in \mathscr{C}(K)$ be a pointwise bounded and equicontinuous sequence on $K$. Then
    \begin{itemize}
        \item[(a)] $f_n$ is uniformly bounded on $K$
        \item[(b)] $f_n$ contains a uniformly convergent subsequence
    \end{itemize}

    \textbf{Proof}

    Let $\varepsilon >0$ be given and choose $\delta > 0$. Since $f_n$ is equicontinuous, choose $\delta$ such that
    \[|f_n(x) - f_n(y)| < \varepsilon\]
    for all $n$ and $d(x, y) < \varepsilon$. Since $K$ is compact, we can cover it with finitely many $\delta$-balls centered at $p_1, \ldots p_r$. 

    Since $f_n$ is pointwise convergent, we may bound each $|f_n(p_i)|$ by some $\varphi(p_i)$. Since we have only finitely many $p_i$, we may take $M := \max \{\varphi(p_1), \ldots, \varphi(p_r)\}$Then $|f_n(p_i)| < M$ for all $i$, hence $|f_n(x)| < M + \varepsilon$ for all $x \in K$ by the triangle inequality. Hence $f_n$ is uniformly bounded.

    Now, for (b), let $E$ be a countable dense subset of $K$. (Existence is guaranteed-- compact metric spaces are separable)

    Now use the previous theorem that tells us there is a subsequence $f_{n_k}$ that converges pointwise on $E$.

    Denote this subsequence by $g_k := f_{n_k}$. Now let $\varepsilon > 0$ and $\delta > 0$ be the same as before. Since $E$ is dense and $K$ is compact, we may cover $K$ with finitely many open balls $B(x_i; \delta)$ centered at points $x_1, \ldots, x_m$ of radius $\delta$. In other words,
    \[K \subset B(x_1; \delta) \cup \cdots \cup B(x_m; \delta)\]
    Then we can use $x_i$ as a bridge to connect $g_j(x)$ and $g_k(x)$: By the pointwise convergence of $g_k$, we know that we can choose $N$ such that $j, k \geq N$ implies 
    \[|g_j(x_i) - g_k(x_i)| < \varepsilon\]
    Let $x$ belong to $B(x_i; \delta)$, then
    \[|g_j(x) - g_j(x_i)| < \varepsilon\]
    Then we construct a big triangle inequality:
    \[|g_j(x) - g_k(x)| \leq |g_j(x) - g_j(x_i)| + |g_j(x_i) - g_k(x_i)| + |g_k(x_i) - g_k(x)| < 3\varepsilon\]
    Which proves that $\Vert g_j - g_k \Vert < 3\varepsilon$, hence $g_k$ is uniformly convergent.
\end{theorem}

WOOHOO!

Now we approach the big theorem this chapter is leading up to: the \textit{Stone-Weierstrass Theorem}.

\subsection{The Stone-Weierstrass Theorem}

\begin{theorem} Weierstrass Approximation Theorem

    Let $f: [a, b] \to \mathbb{C}$ be a continuous function. Then there exists a sequence of polynomials $P_n$ such that $P_n \to f$ uniformly on $[a, b]$. Moreover, if $f$ is real, then each $P_n$ is real.
\end{theorem}

First, some housekeeping is in order.

\begin{theorem} Proof of W.A.T, Part 0: Setup

    It suffices to prove the theorem for functions $f \in \mathscr{C}([a, b])$ such that 
    \begin{itemize}
        \item[(a)] $[a, b] = [0,1]$
        \item[(b)] $f(0) = f(1) = 0$
    \end{itemize}
    to prove the theorem in general.

    \textbf{Proof}

     The first is justified via horizontal shifts and dilations, the second is justified by shears on the $y$ axis. 
\end{theorem}

Then, we start the proof

\begin{plan} Proof of W.A.T, Part 1: Strategy

    We use \textit{convolution}, which is a tool that analyzes a function $f$ by multiplying it with a function $g$ at the point of interest. 

    One use of convolution is to isolate segments of $f$ by using a $g$ that is zero, or very close to zero, outside a neighborhood of the point we wish to study. An example of this would be using very tall Gaussians. Moreover, if the integral of this $g$ is $1$, the value of the convolution integral will almost be $f(x)$ itself!

    Luckily, there is a sequence of polynomials $Q_n$ which do this task well. More luckily, the convolution of \textit{any function at all} with a polynomial results in a polynomial! This gives us an on-the-nose way of \textit{constructing} the polynomials we want-- taking the convolution of $f$ and $Q_n$.
    
    Finally, we show that this sequence really works-- that it really does converge to $f$ in the uniform limit.
\end{plan}

We have to define convolution

\begin{definition} Convolution

    Let $f \in \mathscr{C}([a,b])$ and $g \in \mathscr{C}([c, d])$. Assume that $f$ and $g$ are defined to be $0$ outside their domains. The \textit{convolution} $f \ast g$ is defined to be
    \[(f \ast g)(x) := \int_a^b f(t)g(x-t) dt\]
    This is guaranteed to exist, by Theorem 6.13. 
\end{definition}

\begin{theorem} Proof of W.A.T, Part 2: Constructing the sequence

    Define the polynomial $Q_n := c_n(1-x^2)^n$, where $c_n$ is chosen such that
    \[\int_{-1}^1 Q_n(x)dx = 1\]

    Then define
    \[P_n := f \ast Q_n\]

    Then $P_n$ is a sequence of polynomials.

    \textbf{Proof}

    \begin{lemma} Convolution with a polynomial is a polynomial

        Let $P \in \mathscr{C}([-1, 1])$ be a polynomial, and $f \in \mathscr{C}([0, 1])$, then $f \ast P$ is a polynomial.
        \textbf{Proof}

        By linearity of convolution, we can consider the case $P(x) := x^n$ without loss of generality. Then
        \[(f \ast P) = \int_0^1 f(t)(x-t)^ndt = \int_0^1 f(t) \left[\sum_{k=0}^n \binom{n}{k}x^{n}(-t)^{n-k}\right]dt\]
        \[= \sum_{k=0}^n x^n \left[\binom{n}{k}\int_0^1 f(t) (-t)^{n-k}dt\right]\]
        \[= \sum_{k=0}^n x^n \left[(-1)^{n-k}\binom{n}{k}\int_0^1 f(t)t^{n-k}dt\right]\]
        Which is evidently a polynomial. The coefficient is guaranteed to exist, as $f(t) \cdot t^{n-k}$ is continuous on $[a, b]$, hence the integral in the brackets is defined.
    \end{lemma}

\end{theorem}


\begin{theorem} Proof of W.A.T, Part 3: Convergence

    $P_n \rightarrow f$ uniformly on $[0, 1]$.

    \textbf{Proof}
    
    By symmetry of convolution (change of variables), we have that
    \[P_n = \int_{-1}^1 Q_n(t)f(x-t)dt\]
    Then,
    \[|P_n(x) - f(x)| = \left|\int_{-1}^1 Q_n(t) f(x-t) - f(x)\right|\] 
    Since $\int_{-1}^1 Q_n(t)dt = 1$,
\[|P_n(x) - f(x)| =\left|\int_{-1}^1 Q_n(t)f(x-t) dt - \left[\int_{-1}^1 Q_n(t)dt\right]f(x)\right|\]
Hence
\[|P_n(x) - f(x)| =\left|\int_{-1}^1 Q_n(t)[f(x-t)-f(x)] dt\right|\]
Using the Schwarz inequality and the fact that $Q_n$ is nonnegative, 
\[|P_n(x) - f(x)| \leq \int_{-1}^1 Q_n(t)\big|f(x-t)-f(x)\big| dt\]
The idea now is to divide this integral, which measures the error of the polynomial approximation, into a ``local'' and a ``non-local'' part. The local error's can be bounded by $f$'s uniform continuity, the non-local part can be bounded by $Q_n$ shrinking outside of $t$.

Now, choose $\varepsilon > 0$. We can find $\delta$ such that 
\[|f(y) - f(x)| < \varepsilon/2\]
for all $x, y$ such that $|y-x| < \delta$. This tells us that 
\[|f(x-t) - f(x)| < \varepsilon/2\]
for all $t \in (-\delta, \delta)$. Hence
\[\int_{-\delta}^\delta |f(x-t) - f(x)| Q_n(t) dt < \frac{\varepsilon}{2}\int_{-\delta}^\delta Q_n(t) < \frac{\varepsilon}{2}\]

This is our ``local" error. Our ``non-local'' error is then
\[\int_{-1}^{-\delta} |f(x-t)-f(x)|Q_n(t)dt + \int_{\delta}^1 |f(x-t)-f(x)|Q_n(t)dt\]
\end{theorem}

\begin{consequence}
    The book uses the inequality $c_n < \sqrt{n}$ to derive
    \[Q_n(x) \leq \sqrt{n}(1-\delta^2)^n\]
    Which we will just use at face-value because life is too short. Letting $M = \sup |f(x)|$, we have that $|f(x-t) - f(x)| \leq 2M$, hence, taking it all together, 
\[\int_{-1}^{-\delta} |f(x-t)-f(x)|Q_n(t)dt + \int_{\delta}^1 |f(x-t)-f(x)|Q_n(t)dt\]
\[\leq 2M \int_{-1}^{-\delta}Q_n(t)dt + 2M \int_{\delta}^{1}Q_n(t)dt\]
\[\leq 4M \sqrt{n}(1-\delta^2)^n\]
Which can be made to be less than $\varepsilon/2$ by making $n$ large enough.
\end{consequence}

A special case of the above is used to prove Stone's generalization of the Weierstrass approximation theorem.

\begin{theorem} Polynomial approximation of absolute value

    For every interval $[-a, a]$, there is a sequence of real polynomials $P_n$ such that $P_n(0) = 0$ and such that
    \[\lim_{n \to \infty} P_n(x) = |x|\]
    uniformly on $[-a, a]$

    \textbf{Proof}

    Let $P_n^\ast \rightarrow |x|$ uniformly using the previous theorem. Let 
    \[P_n(x) := P_n^\ast(x) - P_n^\ast(0)\]
    Then $P_n(0) = 0$, and $P_n \rightarrow |x|$ uniformly, as can be read off from the inequality
    \[|P_n(x) - |x|| \leq |P_n^\ast(0)| + |P_n^\ast(x) - |x||\]
    and the fact $P_n^\ast(0) \to 0$ as $n \to 0$
\end{theorem}

Now we define the spaces for which the Stone-Weierstrass Theorem applies.

\begin{definition} Algebras of complex functions

    A family $\mathscr{A}$ of complex-valued functions $f: E \rightarrow \mathbb{C}$ is an \textit{algebra} if $f, g \in \mathscr{A}$ implies 
    \begin{definition}
        \item[(i)] $f + g \in \mathscr{A}$
        \item[(ii)] $fg \in \mathscr{A}$
        \item[(iii)] $cf \in \mathscr{A}$ for all $c \in \mathbb{C}$
    \end{definition}
\end{definition}

For example, the set of all polynomials is an algebra.

\begin{definition} Uniformly closed algebras and uniform closures

    Let $\mathscr{A}$ be an algebra. Let $f_n \in \mathscr{A}$. If $f_n \rightarrow f$ uniformly implies $f \in \mathscr{A}$, then $\mathscr{A}$ is \textit{uniformly closed}

    Let $\mathscr{B}$ be the set of all functions which are limits of uniformly convergent sequences in $\mathscr{A}$. Then $\mathscr{B}$ is called the \textit{uniform closure} of $\mathscr{A}$
\end{definition}

The Weierstrass theorem can be rephrased to mean that the set of continuous functions functions on $[a, b]$ is the uniform closure of the set of polynomials on $[a, b]$

\begin{theorem} Uniform closures of bounded algebras are uniformly closed

    Let $\mathscr{B}$ be the uniform closure of an algebra $\mathscr{A}$ of bounded functions. Then $\mathscr{B}$ is uniformly closed.

    \textbf{Proof}

    Let $f,g \in \mathscr{B}$. Then there exist sequences $f_n, g_n \in \mathscr{A}$ such that $f_n \to f$ and $g_n \to g$ uniformly. Since the functions are bounded, limits pass through easily.
\end{theorem}

\begin{definition} Separating and non-vanishing families of functions

    Let $\mathscr{A}$ be a family of functions on a set $E$. If, for all $x_1, x_2 \in E$, there exists a function $f \in \mathscr{A}$ such that $f(x_1) \neq f(x_2)$, then $\mathscr{A}$ is said to \textit{separate points on $E$}

    If, for all $x \in E$, there exists a function $f \in \mathscr{A}$ such that $f(x) \neq 0$, then $f$ \textit{vanishes at no point of $E$} 
\end{definition}

These two conditions allow us to ``stitch together'' functions to take on values we want at the points we want. More precisely

\begin{theorem}
    {A f}

    Let $\mathscr{A}$ be an algebra on $E$ that separates points and vanishes at no point. Let $x_1, x_2$ be distinct points of $E$, and let $c_1, c_2$ be any two constants. Then there exists $f \in \mathscr{A}$ such that
    \[f(x_1) = c_1 \qquad f(x_2) = c_2\]

    \textbf{Proof}

    Since $\mathscr{A}$ separates points, let $g$ be a function such that 
    \[g(x_1) \neq g(x_2)\]
    The ``trick'' now is to consider the expression $d_{ij} := g(x_i) - g(x_j)$. Clearly, $d_{ij}$ is zero if $i = j$ and nonzero if $i \neq j$. Let's try to normalize it to obtain a function 
    \[\delta_{ij} = \begin{cases}
        1 & i \neq j  \\
        0 & i = j
    \end{cases}\]
    $\delta_{ij} := d_{ij}/d_{12}$ works. However, we have a problem-- we've done \textit{addition by a constant} in defining $d_{ij}$. That's not one of the actions we can generally do in an algebra. Here, we use $\mathscr{A}$'s non-vanishing to our advantage. Let $h_1$ and $h_2$ be functions such that
    \[h_1(x_1) \neq 0 \qquad h_2(x_2) \neq 0\]
    Then, we can add a layer of indirection. Since
\end{theorem}
The following are useful criteria for uniform convergence. These hint at the idea of being able to make sense of the idea of ``distance'' between two functions, which Rudin makes precise later. The first one tells us that uniform convergence of functions corresponds to convergence (via the Cauchy criterion) with respect to a certain kind of metric. 

\begin{theorem}Cauchy criterion for uniform convergence

    $f_n$ converges uniformly on $E$ if and only if there exists an integer $N$ such that for all $m, n \geq N$,
    \[\sup_{x \in E}|f_n(x) - f_m(x)| \leq \varepsilon\]

    \textbf{Proof}

    For the forward implication, let $f_n \rightarrow f$ uniformly, then choose $N$ such that $n \geq N$ implies 
    \[|f_n(x) - f(x)| \leq \frac{\varepsilon}{2}\]
    Then use the triangle inequality.

    For the converse, we note that the above criterion is strong enough itself to guarantee $f_n \rightarrow f$ pointwise, hence if we take the inequality
    \[|f_n(x) - f_m(x)| \leq \varepsilon\]
    and let $m \rightarrow \infty$, we recover the original condition for uniform convergence
\end{theorem}

The next criterion is just a rephrasing of the first definition of uniform convergence. It tells us that uniform convergence corresponds to the ``distance'' between two functions vanishing.

\begin{theorem}Supremum criterion for uniform convergence

    $f_n \rightarrow f$ uniformly on $E$ if and only if 
    \[\sup_{x \in E}|f_n(x) - f(x)| \rightarrow 0 \:\text{ as }\: n \rightarrow \infty\]
\end{theorem}

Next, we show that uniform convergence does not share the same failures as pointwise convergence when it comes to passing through important properties and operations. We first take continuity.

\begin{theorem}Continuity is preserved under uniform convergence

    Let $f_n$ be a sequence of continuous functions and let $f_n \rightarrow f$ uniformly. Then $f$ is continuous.

    \textbf{Proof}

    Let $\varepsilon > 0$. Let $x \in E$. Consider the inequality
    \[|f(x) - f(t)| \leq |f(x) - f_n(x)| + |f_n(x) - f_n(t)| + |f_n(t) - f(t)|\]
First use uniform convergence to choose $n$ such that $|f(x) - f_n(x)|$ and $|f(t) - f_n(t)|$ are arbitrarily small. 

Then use continuity to choose $\delta$ such that $|f_n(x) - f_n(t)|$ can be made arbitrarily small by letting $|x-t| \leq \delta$.
\end{theorem}

This however is not an ``if and only if''. A continuous function can be the non-uniform limit of continuous functions. In one case, however, we can use compactness and monotonicity to take enough control such that a sequence of functions can \textit{only} converge uniformly.

\begin{example}Inferring uniform convergence from pointwise convergence
    
    Let $f_n: K \rightarrow \mathbb{R}$ be a sequence of continuous functions, and let $f_n \rightarrow f$ pointwise. Let $f$ be continuous. Impose the two conditions
    \begin{itemize}
        \item Let $K$ be compact
        \item Let $f_n(x) \geq f_{n+1}(x)$ for all $x$ and all $n$
    \end{itemize}
    Then $f_n \rightarrow f$ uniformly.

    \textbf{Proof}

    We must show that, as $n \rightarrow \infty$,
    \[\sup_{x \in E}|f_n(x) - f(x)| \rightarrow 0\]

    To do this, we choose $\varepsilon$ and argue that the set of points for which $|f_n(x) - f(x)| \geq \varepsilon$ can be made empty if we take $n$ large enough. Let this set of exceptional points be $K_n$.


    $K$'s compactness tells us that $K_n$ is compact:
    \begin{itemize}
        \item Because $f_n - f$ is a continuous function and $[\varepsilon, \infty)$ is closed, $K_n = (f_n-f)^{-1}([\varepsilon, \infty))$ is closed. (Theorem 4.8; inverse images of closed sets under continuous functions are closed) 
        \item Because $K_n$ is closed, and $K$ is compact, $K_n$ is compact. (Theorem 2.35; closed subsets of compact spaces are compact).
    \end{itemize}

    Moreover, because of the monotonicity of $f_n$, $K_n \supseteq K_{n+1}$. Hence $K_n$ is a sequence of nested compact sets.

    It must be that $\bigcap K_n$ is empty, as $f_n$ converges pointwise to $f$, and so for each $x$, the fact that $|f_n(x) - f| < \varepsilon$ for some $n$ means there must be some $K_n$ it is not a member of.

    But an intersubsection of nonempty nested compact sets must be nonempty (Theorem 2.36), so there has to be an empty set somewhere in the sequence. Let this set be $K_N$. Then for all $n \geq N$, $K_n$ is empty. This is precisely the $N$ we need to keep the distance between $f_n$ and $f$ below $\varepsilon$.
\end{example}

Restricting our study to continuous, bounded functions (the functions above were bounded because $K$ was compact) gives rise to a very nice structure, one we're already very familiar with: a metric space. (More importantly, a vector space!)

The concept of distance here corresponds with how it has been used in the previous theorems and examples.

\begin{definition}The space of continuous and bounded functions on $X$

    Let $X$ be a metric space. Let $\mathscr{C}(X)$ denote the set of all continuous, bounded, complex-valued functions on $X$.

    Let $f \in \mathscr{C}(X)$. Define the \textit{supremum norm} as follows.
    \[\Vert f \Vert = \sup_{x \in X} |f(x)|\]
    Let $d(f, g)$ for $f, g \in \mathscr{C}(X)$ be induced by the norm; i.e
    \[d(f, g) = \Vert f - g \Vert\]
    This turns $\mathscr{C}(X)$ into a metric space.
\end{definition}

This space is complete, and the fact that it is so can be bootstrapped with the previous theorems.

\begin{consequence} $\mathscr{C}(X)$ is complete
    {Proof}

    Let $f_n$ be a Cauchy sequence in $\mathscr{C}(X)$. Then $f_n$ converges uniformly to a function $f$. Moreover, since each $f_n$ is continuous, $f$ is continuous. That $f$ is bounded follows from the fact that $f = f_n + (f - f_n)$, so $\Vert f \Vert \leq \Vert f_n \Vert + \Vert f - f_n \Vert = \Vert f_n \Vert + \varepsilon$. 

    Hence $f \in \mathscr{C}(X)$. Since $f_n \rightarrow f$ uniformly, $\Vert f - f_n \Vert \rightarrow 0$.
\end{consequence}


Next, we tackle integration. Uniform convergence allows us to bound $f$ in a, well, uniform way. This, along with a version of the squeeze theorem for integrals, shows us that uniform convergence plays nicely with integration.

\begin{theorem} The integral of a uniformly convergent limit is a uniformly convergent limit of integrals

    Let $f_n \in \mathscr{R}(\alpha)$ on $[a, b]$ for all $n$. Let $f_n \rightarrow f$ uniformly. Then $f \in \mathscr{R}(\alpha)$, and
    \[\int_a^b f d\alpha = \lim_{n \to \infty} \int_a^b f_n d\alpha\]

    \textbf{Proof}

    The idea is that you can ``squeeze'' $f$ with two $f_n$ shaped calipers, and that the gap decreases as $n$ goes to infinity.

    Let this gap be 
    \[\varepsilon_n = \Vert f_n - f\Vert\]
    Then
    \[f_n - \varepsilon_n \leq f \leq f_n + \varepsilon_n\]
    Then this bounds $f$'s lower and upper integrals.
    \[\int_a^b (f_n-\varepsilon_n) d\alpha \leq \underline{\int} f d\alpha \leq \overline{\int} f d\alpha \leq \int_a^b (f_n+\varepsilon_n) d\alpha\]
    Then
    \[0 \leq \overline{\int} f d\alpha - \underline{\int} fd\alpha \leq 2 \varepsilon(\alpha(b) - \alpha(a)) \]
    So $f \in \mathscr{R}(\alpha)$. From the inequality we can also read off 
    \[\left| \int_a^b fd\alpha - \int_a^b f_nd\alpha\right| \leq \varepsilon_n (\alpha(b) - \alpha(a))\]
    Which proves the equality of the integral and the limit.
\end{theorem}
    
Finally, we look at differentiation.

\begin{theorem} A sequence of functions whose derivatives converge uniformly converges uniformly to a limit with the correct derivative

    Let $f_n: [a,b] \rightarrow \mathbb{R}$ be a sequence of differentiable functions that converge pointwise for at least \textit{some} point $x_0$. Then if $f_n'$ converge uniformly, there is a function $f$ such that $f_n \rightarrow f$ uniformly and such that $f_n' \rightarrow f'$.

    \textbf{Proof}

    Let $\varepsilon > 0$. Use the Cauchy criterion for both ordinary sequences in $\mathbb{R}$ and for uniformly convergent sequences of functions to produce $N$ such that $n, m \geq N$ implies
    \[|f_n(x_0) - f_m(x_0)| \leq \frac{\varepsilon}{2}\]
    \[\Vert f'_n - f'_m \Vert \leq \frac{\varepsilon}{2(b-a)}\]
    Consider the function $f_n - f_m$, whose derivative is $f'_n - f'_m$. The mean value theorem gives us a $c$ with which we can show
    \[\left|\frac{[f_n(x) - f_m(x)] - [f_n(y) - f_m(y)]}{x-y}\right| = |f'_n(c) - f'_m(c)| \leq \Vert f'_n - f'_m \Vert \leq \frac{\varepsilon}{2(b-a)}\]
    Then, since $a \leq x < y \leq b$
    \[\left|[f_n(x) - f_m(x)] - [f_n(y) - f_m(y)]\right| \leq \frac{\varepsilon|x-y|}{2(b-a)} \leq \frac{\varepsilon}{2}\]
    for any $x, y \in [a, b]$. Then, by the triangle inequality,
    \[|f_n(x) - f_m(x)| \leq |[f_n(x) - f_m(x)] - [f_n(x_0) - f_m(x_0)]| + |f_n(x_0) - f_m(x_0)| \leq \varepsilon\]
    Then $f_n$ converges uniformly by the Cauchy criterion.

    Next we prove that the derivative of the limit is the limit of the derivatives. Let $f_n \rightarrow f$. Define the difference quotients
    \[\phi_n(t) := \frac{f_n(t) - f_n(x)}{t-x}\]
    \[\phi(t) := \frac{f(t) - f(x)}{t-x}\]
    Reusing the same inequality, we know that for $n, m \geq N$
    \[|\phi_n(t) - \phi_m(t)| \leq \frac{\varepsilon}{2(b-a)}\]
    So that $\phi_n \rightarrow \phi$ uniformly. Then, by Theorem 7.11, the limits we are interested in commute:
    \[\lim_{t \to x} \lim_{n \to \infty} \phi_n(t) = \lim_{n \to \infty} \lim_{t \to x} \phi_n(t)\]
    The left hand side is $f'(x)$
    \[\lim_{t \to x} \lim_{n \to \infty} \phi_n(t) = \lim_{t \to x} \phi(t) = f'(x)\]
    The right hand side is $\lim_{n\to\infty} f'_n(x)$
    \[\lim_{n \to \infty} \lim_{t \to x} \phi_n(t) = \lim_{n \to \infty} f'_n(x)\]
    Hence $f'_n \rightarrow f_n$.
\end{theorem}

Now with the machinery of limits of function sequences, we can explore a wider variety of functions. As an example.

\begin{example}A nowhere differentiable continuous function

    Define the periodic triangle function $\varphi$ to be
    \[\varphi(x) := |x|\]
    for $0 < x \leq 1$, and let its periodicity be defined by
    \[\varphi(x+2) := \varphi(x)\] 
    Then $\varphi$ is continuous. Define $f$ as
    \[f(x) := \sum_{n=0}^\infty \left(\frac{3}{4}\right)^n \varphi(4^nx)\]
    By Theorem 7.10, the series converges uniformly. Then $f$ is continuous, as it is a uniformly convergent sequence of continuous functions.
     To prove it is not differentiable, we construct a sequence $x_n \rightarrow x$ such that the difference quotient diverges. I haven't looked into it deeply yet.
 \end{example}

\subsection{Equicontinuous families of functions}

Now we go up another level. How do we \textit{produce} these uniformly convergent sequences of functions out of existing sequences? The same way we have conditions (boundedness in $\mathbb{R}^n$) for squeezing out convergent sequences of numbers? First consider two different kinds of boundedness.

\begin{definition} Pointwise and uniform boundedness
    
    Let $f_n: E \rightarrow \mathbb{R}$ be a sequence of functions.

    $f_n$ is \textit{pointwise bounded} if for some $\varphi: E \rightarrow \mathbb{R}$,
    \[|f_n(x)| < \varphi(x)\]
    $f_n$ is \textit{uniformly bounded} if for some $M \geq 0$,
    \[|f_n(x)| < M\]
    It is clear that uniform boundedness implies pointwise boundedness, by letting $\phi(x) := M$.
\end{definition}

There are, however, no easy analogues, even when we put together all the restrictions we've considered so far:

\begin{example} A uniformly bounded sequence of continuous functions on a compact set without a convergent subsequence

    Let $f_n: [0, 2\pi] \to \mathbb{R}$ be defined 
    \[f_n(x) := \sin nx\]
    Suppose this sequence has a subsequence $f_{n_k}$ that converges pointwise. Then it must be that
    \[\lim_{k \to \infty} (\sin n_k x - \sin n_{k+1}x) = 0\]
    therefore it must be the case that
    \[\lim_{k \to \infty} (\sin n_k x - \sin n_{k+1}x)^2 = 0\]
    By Lebesgue's theorem concerning integration of boundedly convergent sequences (Theorem 11.32), this implies
    \[\lim_{k \to \infty} \int_0^{2\pi} (\sin n_k x - \sin n_{k+1} x)^2 dx = 0\]
    But 
    \[\int_0^{2\pi} (\sin n_k x - \sin n_{k+1} x)^2 dx = 2\pi\]
    which is a contradiction.
\end{example}

Even if we have a (pointwise) convergent sequence, we cannot produce a uniformly convergent subsequence necessarily, even with uniform boundedness on a compact set.

\begin{example} A uniformly bounded pointwise converging sequence on a compact set without a uniformly convergent subsequence

    Let $f_n: [0, 1] \rightarrow \mathbb{R}$ be
    \[f_n(x) = \frac{x^2}{x^2+(1-nx)^2}\]
    Then $|f_n| \leq 1$ for all $n$, and $f_n$ is a uniformly bounded sequence. $f_n(x) \to 0$ for all $x$ as $n \to \infty$ as well, so this sequence converges pointwise.
    However,
    \[f_n\left(\frac{1}{n}\right) = 1\]
    so that no subsequence can possibly converge uniformly.
\end{example}

However, we know that compact sets are separable (have a dense countable subset), hence the following consequence of pointwise boundedness will be useful:

\begin{theorem} Every pointwise bounded sequence has a subsequence that converges pointwise on a countable set

    Let $f_n$ be defined on a countable set $E$. (Or define it on an arbitrary set, and let $f_n$ be the restriction on a countable set $E$).

    Then there exists a subsequence $f_{n_k}$ of $f_n$ such that $f_{n_k}$ converges pointwise on $E$.

    \textbf{Proof}

    We will construct a table of $f_n$ of which taking the diagonal will give us the subsequence we want. To do so, we introduce a lemma

    \begin{lemma}
    \textbf{Lemma}

    Let $s_n$ be a bounded sequence. Then it contains a convergent subsequence $s_{n_k}$ that may be obtained by simply deleting entries in $s_n$.
    \end{lemma}

    This table will be defined row-by-row

    Let $x_i$ be an enumeration of $E$. Since $f_n$ is pointwise bounded, we can produce a subsequence $f_{n_k}$ such that $f_{n_k}(x_1)$ converges as $k \to \infty$. Denote this sequence by $f^1_k$. 

    Then in a similar fashion, we recursively construct the following sequences $f^{i+1}_k$ out of $f^i_k$ using the above lemma. This results in a table of functions
    \[\begin{matrix}
        f^1_1 & f^1_2 & f^1_3 & \cdots \\
        f^2_1 & f^2_2 & f^2_3 & \cdots \\
        f^3_1 & f^3_2 & f^3_3 & \cdots \\
        \vdots & \vdots & \vdots & \ddots
    \end{matrix}\]

    which satisfy the properties
    \begin{itemize}
        \item[(a)] $f^{i+1}_k$ is a subsequence of $f^i_k$, moreover it is simply $f^i_k$ with entries deleted. 
        \item[(b)] $f^i_k(x_i)$ converges as $k \to \infty$
    \end{itemize}

    Then, if we take the diagonal
    \[f^1_1, f^2_2,  f^3_3, \ldots\] 
    (a) implies that this sequence is a subsequence of all $f^i_k$, thus (b) implies that this sequence converges for all $x_i$.
\end{theorem}

Now we introduce an important property 

\begin{definition} Equicontinuous families of functions

    Let $\mathscr{F}$ be a family of complex-valued functions $f$ defined on a set $E$. $\mathscr{F}$ is \textit{equicontinuous} if for every $\varepsilon > 0$ there exists $\delta > 0$ such that
    \[|f(x) - f(y)| < \varepsilon\]
    whenever $d(x, y) < \delta$.
\end{definition}

We get one result almost ``for free'' with this definition

\begin{theorem} Uniformly convergent continuous function sequences on a compact domain form an equicontinuous family

    Let $K$ be a compact metric space, and let $f_n \in \mathscr{C}(K)$ be a uniformly convergent sequence on $K$. Then $f_n$ is equicontinuous on $K$

    \textbf{Proof}

    Let $\varepsilon > 0$. Since $f_n$ converges in $\mathscr{C}(K)$, we can choose $N$ such that
    \[\Vert f_n - f_N \Vert < \varepsilon\]
    whenever $n > N$. Now, use the fact that continuous functions on compact sets are uniformly continuous (Theorem 4.19) to find $\delta_N > 0$ such that 
    \[|f_N(x) - f_N(y)| < \varepsilon\]
    whenever $d(x, y) < \delta_N$. This alone evidently covers the case $n = N$. For $n > N$, we have the following inequality,
    \[|f_n(x) - f_n(y)| \leq |f_n(x) - f_N(x)| + |f_N(x) - f_N(y)| + |f_N(y) - f_n(y)| < 3\varepsilon\]
    Hence we have shown that $\delta_N$ suffices for $n \geq N$. For $n < N$, use uniform continuity for each $f_n$ to get $\delta_n$ be such that $d(x, y) < \delta_n$ implies
    \[|f_i(x) - f_i(y)| < \varepsilon\]
    Finally, let $\delta = \min \{\delta_1, \ldots, \delta_N\}$. This $\delta$ satisfies the condition for all $n > 0$.
\end{theorem}

The next result uses the earlier theorem about pointwise converging subsequences on a countable set.

\begin{theorem} Arzel\'a-Ascoli

    Let $K$ be a compact metric space. Let $f_n \in \mathscr{C}(K)$ be a pointwise bounded and equicontinuous sequence on $K$. Then
    \begin{itemize}
        \item[(a)] $f_n$ is uniformly bounded on $K$
        \item[(b)] $f_n$ contains a uniformly convergent subsequence
    \end{itemize}

\end{theorem}


\begin{proof}
    Let $\varepsilon >0$ be given and choose $\delta > 0$. Since $f_n$ is equicontinuous, choose $\delta$ such that
    \[|f_n(x) - f_n(y)| < \varepsilon\]
    for all $n$ and $d(x, y) < \varepsilon$. Since $K$ is compact, we can cover it with finitely many $\delta$-balls centered at $p_1, \ldots p_r$. 

    Since $f_n$ is pointwise convergent, we may bound each $|f_n(p_i)|$ by some $\varphi(p_i)$. Since we have only finitely many $p_i$, we may take $M := \max \{\varphi(p_1), \ldots, \varphi(p_r)\}$Then $|f_n(p_i)| < M$ for all $i$, hence $|f_n(x)| < M + \varepsilon$ for all $x \in K$ by the triangle inequality. Hence $f_n$ is uniformly bounded.

    Now, for (b), let $E$ be a countable dense subset of $K$. (Existence is guaranteed-- compact metric spaces are separable)

    Now use the previous theorem that tells us there is a subsequence $f_{n_k}$ that converges pointwise on $E$.

    Denote this subsequence by $g_k := f_{n_k}$. Now let $\varepsilon > 0$ and $\delta > 0$ be the same as before. Since $E$ is dense and $K$ is compact, we may cover $K$ with finitely many open balls $B(x_i; \delta)$ centered at points $x_1, \ldots, x_m$ of radius $\delta$. In other words,
    \[K \subset B(x_1; \delta) \cup \cdots \cup B(x_m; \delta)\]
    Then we can use $x_i$ as a bridge to connect $g_j(x)$ and $g_k(x)$: By the pointwise convergence of $g_k$, we know that we can choose $N$ such that $j, k \geq N$ implies 
    \[|g_j(x_i) - g_k(x_i)| < \varepsilon\]
    Let $x$ belong to $B(x_i; \delta)$, then
    \[|g_j(x) - g_j(x_i)| < \varepsilon\]
    Then we construct a big triangle inequality:
    \[|g_j(x) - g_k(x)| \leq |g_j(x) - g_j(x_i)| + |g_j(x_i) - g_k(x_i)| + |g_k(x_i) - g_k(x)| < 3\varepsilon\]
    Which proves that $\Vert g_j - g_k \Vert < 3\varepsilon$, hence $g_k$ is uniformly convergent.
\end{proof}

\subsection{The Stone-Weierstrass Theorem}

\begin{theorem} Weierstrass Approximation Theorem

    Let $f: [a, b] \to \mathbb{C}$ be a continuous function. Then there exists a sequence of polynomials $P_n$ such that $P_n \to f$ uniformly on $[a, b]$. Moreover, if $f$ is real, then each $P_n$ is real.
\end{theorem}

First, some housekeeping is in order.

\begin{theorem} Proof of W.A.T, Part 0: Setup

    It suffices to prove the theorem for functions $f \in \mathscr{C}([a, b])$ such that 
    \begin{itemize}
        \item[(a)] $[a, b] = [0,1]$
        \item[(b)] $f(0) = f(1) = 0$
    \end{itemize}
    to prove the theorem in general.

    \textbf{Proof}

     The first is justified via horizontal shifts and dilations, the second is justified by shears on the $y$ axis. 
\end{theorem}

Then, we start the proof

\begin{plan} Proof of W.A.T, Part 1: Strategy

    We use \textit{convolution}, which is a tool that analyzes a function $f$ by multiplying it with a function $g$ at the point of interest. 

    One use of convolution is to isolate segments of $f$ by using a $g$ that is zero, or very close to zero, outside a neighborhood of the point we wish to study. An example of this would be using very tall Gaussians. Moreover, if the integral of this $g$ is $1$, the value of the convolution integral will almost be $f(x)$ itself!

    Luckily, there is a sequence of polynomials $Q_n$ which do this task well. More luckily, the convolution of \textit{any function at all} with a polynomial results in a polynomial! This gives us an on-the-nose way of \textit{constructing} the polynomials we want-- taking the convolution of $f$ and $Q_n$.
    
    Finally, we show that this sequence really works-- that it really does converge to $f$ in the uniform limit.
\end{plan}

We have to define convolution

\begin{definition} Convolution

    Let $f \in \mathscr{C}([a,b])$ and $g \in \mathscr{C}([c, d])$. Assume that $f$ and $g$ are defined to be $0$ outside their domains. The \textit{convolution} $f \ast g$ is defined to be
    \[(f \ast g)(x) := \int_a^b f(t)g(x-t) dt\]
    This is guaranteed to exist, by Theorem 6.13. 
\end{definition}

\begin{theorem} Proof of W.A.T, Part 2: Constructing the sequence

    Define the polynomial $Q_n := c_n(1-x^2)^n$, where $c_n$ is chosen such that
    \[\int_{-1}^1 Q_n(x)dx = 1\]

    Then define
    \[P_n := f \ast Q_n\]

    Then $P_n$ is a sequence of polynomials.

    \textbf{Proof}

    \begin{lemma} Convolution with a polynomial is a polynomial

        Let $P \in \mathscr{C}([-1, 1])$ be a polynomial, and $f \in \mathscr{C}([0, 1])$, then $f \ast P$ is a polynomial.
        \textbf{Proof}

        By linearity of convolution, we can consider the case $P(x) := x^n$ without loss of generality. Then
        \[(f \ast P) = \int_0^1 f(t)(x-t)^ndt = \int_0^1 f(t) \left[\sum_{k=0}^n \binom{n}{k}x^{n}(-t)^{n-k}\right]dt\]
        \[= \sum_{k=0}^n x^n \left[\binom{n}{k}\int_0^1 f(t) (-t)^{n-k}dt\right]\]
        \[= \sum_{k=0}^n x^n \left[(-1)^{n-k}\binom{n}{k}\int_0^1 f(t)t^{n-k}dt\right]\]
        Which is evidently a polynomial. The coefficient is guaranteed to exist, as $f(t) \cdot t^{n-k}$ is continuous on $[a, b]$, hence the integral in the brackets is defined.
    \end{lemma}

\end{theorem}


\begin{theorem} Proof of W.A.T, Part 3: Convergence

    $P_n \rightarrow f$ uniformly on $[0, 1]$.

    \textbf{Proof}
    
    By symmetry of convolution (change of variables), we have that
    \[P_n = \int_{-1}^1 Q_n(t)f(x-t)dt\]
    Then,
    \[|P_n(x) - f(x)| = \left|\int_{-1}^1 Q_n(t) f(x-t) - f(x)\right|\] 
    Since $\int_{-1}^1 Q_n(t)dt = 1$,
\[|P_n(x) - f(x)| =\left|\int_{-1}^1 Q_n(t)f(x-t) dt - \left[\int_{-1}^1 Q_n(t)dt\right]f(x)\right|\]
Hence
\[|P_n(x) - f(x)| =\left|\int_{-1}^1 Q_n(t)[f(x-t)-f(x)] dt\right|\]
Using the Schwarz inequality and the fact that $Q_n$ is nonnegative, 
\[|P_n(x) - f(x)| \leq \int_{-1}^1 Q_n(t)\big|f(x-t)-f(x)\big| dt\]
The idea now is to divide this integral, which measures the error of the polynomial approximation, into a ``local'' and a ``non-local'' part. The local error's can be bounded by $f$'s uniform continuity, the non-local part can be bounded by $Q_n$ shrinking outside of $t$.

Now, choose $\varepsilon > 0$. We can find $\delta$ such that 
\[|f(y) - f(x)| < \varepsilon/2\]
for all $x, y$ such that $|y-x| < \delta$. This tells us that 
\[|f(x-t) - f(x)| < \varepsilon/2\]
for all $t \in (-\delta, \delta)$. Hence
\[\int_{-\delta}^\delta |f(x-t) - f(x)| Q_n(t) dt < \frac{\varepsilon}{2}\int_{-\delta}^\delta Q_n(t) < \frac{\varepsilon}{2}\]

This is our ``local" error. Our ``non-local'' error is then
\[\int_{-1}^{-\delta} |f(x-t)-f(x)|Q_n(t)dt + \int_{\delta}^1 |f(x-t)-f(x)|Q_n(t)dt\]
\end{theorem}

\begin{proposition}
    The book uses the inequality $c_n < \sqrt{n}$ to derive
    \[Q_n(x) \leq \sqrt{n}(1-\delta^2)^n\]
    Which we will just use at face-value because life is too short. Letting $M = \sup |f(x)|$, we have that $|f(x-t) - f(x)| \leq 2M$, hence, taking it all together, 
\[\int_{-1}^{-\delta} |f(x-t)-f(x)|Q_n(t)dt + \int_{\delta}^1 |f(x-t)-f(x)|Q_n(t)dt\]
\[\leq 2M \int_{-1}^{-\delta}Q_n(t)dt + 2M \int_{\delta}^{1}Q_n(t)dt\]
\[\leq 4M \sqrt{n}(1-\delta^2)^n\]
Which can be made to be less than $\varepsilon/2$ by making $n$ large enough.
\end{proposition}

A special case of the above is used to prove Stone's generalization of the Weierstrass approximation theorem.

\begin{theorem}Polynomial approximation of absolute value

    For every interval $[-a, a]$, there is a sequence of real polynomials $P_n$ such that $P_n(0) = 0$ and such that
    \[\lim_{n \to \infty} P_n(x) = |x|\]
    uniformly on $[-a, a]$

    \textbf{Proof}

    Let $P_n^\ast \rightarrow |x|$ uniformly using the previous theorem. Let 
    \[P_n(x) := P_n^\ast(x) - P_n^\ast(0)\]
    Then $P_n(0) = 0$, and $P_n \rightarrow |x|$ uniformly, as can be read off from the inequality
    \[|P_n(x) - |x|| \leq |P_n^\ast(0)| + |P_n^\ast(x) - |x||\]
    and the fact $P_n^\ast(0) \to 0$ as $n \to 0$
\end{theorem}

Now we define the spaces for which the Stone-Weierstrass Theorem applies.

\begin{definition}Algebras of complex functions

    A family $\mathscr{A}$ of complex-valued functions $f: E \rightarrow \mathbb{C}$ is an \textit{algebra} if $f, g \in \mathscr{A}$ implies 
    \begin{itemize}
        \item[(i)] $f + g \in \mathscr{A}$
        \item[(ii)] $fg \in \mathscr{A}$
        \item[(iii)] $cf \in \mathscr{A}$ for all $c \in \mathbb{C}$
    \end{itemize}
\end{definition}

For example, the set of all polynomials is an algebra.

\begin{definition}Uniformly closed algebras and uniform closures

    Let $\mathscr{A}$ be an algebra. Let $f_n \in \mathscr{A}$. If $f_n \rightarrow f$ uniformly implies $f \in \mathscr{A}$, then $\mathscr{A}$ is \textit{uniformly closed}

    Let $\mathscr{B}$ be the set of all functions which are limits of uniformly convergent sequences in $\mathscr{A}$. Then $\mathscr{B}$ is called the \textit{uniform closure} of $\mathscr{A}$
\end{definition}

The Weierstrass theorem can be rephrased to mean that the set of continuous functions functions on $[a, b]$ is the uniform closure of the set of polynomials on $[a, b]$

\begin{theorem}Uniform closures of bounded algebras are uniformly closed

    Let $\mathscr{B}$ be the uniform closure of an algebra $\mathscr{A}$ of bounded functions. Then $\mathscr{B}$ is uniformly closed.

    \textbf{Proof}

    Let $f,g \in \mathscr{B}$. Then there exist sequences $f_n, g_n \in \mathscr{A}$ such that $f_n \to f$ and $g_n \to g$ uniformly. Since the functions are bounded, limits pass through easily.
\end{theorem}

\begin{definition}Separating and non-vanishing families of functions

    Let $\mathscr{A}$ be a family of functions on a set $E$. If, for all $x_1, x_2 \in E$, there exists a function $f \in \mathscr{A}$ such that $f(x_1) \neq f(x_2)$, then $\mathscr{A}$ is said to \textit{separate points on $E$}

    If, for all $x \in E$, there exists a function $f \in \mathscr{A}$ such that $f(x) \neq 0$, then $f$ \textit{vanishes at no point of $E$} 
\end{definition}

These two conditions allow us to ``stitch together'' functions to take on values we want at the points we want. More precisely

\begin{theorem} A function that takes two specific values at two points

    Let $\mathscr{A}$ be an algebra on $E$ that separates points and vanishes at no point. Let $x_1, x_2$ be distinct points of $E$, and let $c_1, c_2$ be any two constants. Then there exists $f \in \mathscr{A}$ such that
    \[f(x_1) = c_1 \qquad f(x_2) = c_2\]

    \textbf{Proof}

    Since $\mathscr{A}$ separates points, let $g$ be a function such that 
    \[g(x_1) \neq g(x_2)\]
    The ``trick'' now is to consider the expression $d_{ij} := g(x_i) - g(x_j)$. Clearly, $d_{ij}$ is zero if $i = j$ and nonzero if $i \neq j$. Let's try to normalize it to obtain a function 
    \[\delta_{ij} = \begin{cases}
        1 & i \neq j  \\
        0 & i = j
    \end{cases}\]
    $\delta_{ij} := d_{ij}/d_{12}$ works. However, we have a problem-- we've done \textit{addition by a constant} in defining $d_{ij}$. That's not one of the actions we can generally do in an algebra. Here, we use $\mathscr{A}$'s non-vanishing to our advantage. Let $h_1$ and $h_2$ be functions such that
    \[h_1(x_1) \neq 0 \qquad h_2(x_2) \neq 0\]
    Then, we can add a layer of indirection. Since
\end{theorem}
